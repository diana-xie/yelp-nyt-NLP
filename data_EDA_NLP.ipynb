{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl \n",
    "%matplotlib inline\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyt_yelp = pd.read_pickle('df_nyt_yelp_corrected.pkl') # import nyt-yelp master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews:  72007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool_count</th>\n",
       "      <th>elite_count</th>\n",
       "      <th>friend_count</th>\n",
       "      <th>funny_count</th>\n",
       "      <th>length_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>useful_count</th>\n",
       "      <th>user_count</th>\n",
       "      <th>review_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1771</td>\n",
       "      <td>5</td>\n",
       "      <td>345</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>Davelle, uh, oden, uh. Foodie, why you trippin...</td>\n",
       "      <td>4</td>\n",
       "      <td>Jennie C.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>791</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>Keep It Simple Smart.  Cute all day cafe with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yvonne C.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cool_count  elite_count friend_count funny_count  length_count  rating  \\\n",
       "0          4            1           45           2          1771       5   \n",
       "1          1            1           68           0           791       4   \n",
       "\n",
       "  review_count review_date                                        review_text  \\\n",
       "0          345  2018-06-18  Davelle, uh, oden, uh. Foodie, why you trippin...   \n",
       "1          350  2018-07-01  Keep It Simple Smart.  Cute all day cafe with ...   \n",
       "\n",
       "  useful_count user_count  review_idx  \n",
       "0            4  Jennie C.           0  \n",
       "1            1  Yvonne C.           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "# make a new, second master dataframe that compiles all reviews scraped so far\n",
    "df_reviews = pd.DataFrame()\n",
    "rest_length = []\n",
    "for idx in range(0,280):\n",
    "    pkl_name = 'import/restaurants/' + str(idx) + '.pkl' # get Pickle file name of restaurant\n",
    "    df = pd.read_pickle(pkl_name) # import pickled dataframe\n",
    "    df['review_idx'] = idx # affix restaurant's index to dataframe\n",
    "    df_reviews = df_reviews.append(df) # append to master dataframe of reviews\n",
    "    rest_length.append(len(df))\n",
    "\n",
    "df_reviews = df_reviews.reset_index().drop('index', axis=1)\n",
    "\n",
    "# convert date to DateTime object\n",
    "df_reviews['review_date'] = [parser.parse(t) for t in df_reviews['review_date']]\n",
    "#df_reviews['review_date'] = [datetime.strptime(str(t).split()[0], '%Y-%m-%d') for t in df_reviews['review_date']]\n",
    "\n",
    "# convert rating from str to numeric\n",
    "df_reviews['rating'] = pd.to_numeric(df_reviews['rating'])\n",
    "\n",
    "print('Total number of reviews: ', len(df_reviews))\n",
    "df_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.DataFrame({'yelp_name':df_nyt_yelp['yelp_name'][:238], 'length':rest_length})\n",
    "#test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop invalid restaurants\n",
    "\n",
    "Drop some other restaurants that were discovered to be invalid (not from NYC, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_idx = [34,44,47,151,352,498]\n",
    "df_nyt_yelp = df_nyt_yelp.drop(delete_idx)\n",
    "\n",
    "delete_reviews = [idx for idx, row in df_reviews.iterrows() if row['review_idx'] in delete_idx]\n",
    "df_reviews = df_reviews.drop(delete_reviews).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in master dataframe w/ scraped reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab restaurants that have complete Yelp scraped data now\n",
    "#df_master = df_nyt_yelp.iloc[:`90]\n",
    "\n",
    "# fill in Yelp scraped data\n",
    "#for idx in range(0,88):\n",
    "#    pkl_name = str(idx) + '.pkl'\n",
    "#    df = pd.read_pickle(pkl_name)\n",
    "#    df_master.loc[idx, 'yelp_reviews'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Yelp reviews - NLP corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 NLP pre-processing\n",
    "\n",
    "Generate a pre-processed, tokenized list of documents in preparation for using gensim to create a corpus. Here, a <u>document</u> = a review's text. Each document is converted to a list of pre-processed tokens (not unique - will list all instances of tokens).\n",
    "\n",
    "Pre-processing steps: \n",
    "- Lowercase\n",
    "- Remove non-alphabetic characters/punctuation\n",
    "- Remove stop words\n",
    "- Lemmatize\n",
    "- Correct (some) misspellings w/ [TextBlob](http://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "text_tokenized = []\n",
    "text_preprocessed = []\n",
    "\n",
    "for idx, review in df_reviews.iterrows():\n",
    "\n",
    "    # basic pre-processing\n",
    "    text = review['review_text'].lower() # lowercase doc\n",
    "    text = str(TextBlob(text).correct()) # correct misspellings\n",
    "    text2 = word_tokenize(text) # tokenize doc\n",
    "    text3 = [tok for tok in text2 if tok.isalpha()] # retain only alphabetic words\n",
    "\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english')) # generate stopwords from English dictionary\n",
    "    text4 = [tok for tok in text3 if tok not in stop_words]\n",
    "\n",
    "    # lemmatize tokens\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    text5 = [wordnet_lemmatizer.lemmatize(tok) for tok in text4]\n",
    "\n",
    "    # correct some misspellings\n",
    "    #text6 = [str(TextBlob(tok).correct()) for tok in text5]\n",
    "\n",
    "    text_tokenized.append(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we corrected misspellings with TextBlob, our pre-processing takes a considerable amount of time to run (~18 hours). So we back up the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texttokenized = pd.DataFrame({'idx':np.arange(0,len(text_tokenized)), 'text_tokenized':text_tokenized})\n",
    "df_texttokenized.to_pickle('df_texttokenized.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create corpus w/ gensim\n",
    "\n",
    "We use [gensim](https://radimrehurek.com/gensim/) to create a corpus, where each token is mapped to a unique numerical ID and word count (i.e. bag of words, BoW) in order to set up structure for inputting to NLP algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# create dictionary from list of pre-processed tokens (all instances) across all documents ('lemmatized')\n",
    "dictionary = Dictionary(text_tokenized)\n",
    "\n",
    "# generate corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in text_tokenized] # .doc2bow method converts documents into BoW format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a sample review under our different processing steps leading up to gensim corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review (after pre-processing):  i don't give 5 stars often, unless it was truly a cellar meal. and of course it doesn't have to be a stuffy fancypants place to be cellar, although sometimes it is. shako was one of those scale places and was truly, from the bottom of my heart, one of the best meals i've ever had. it's so adams that the door isn't even marked- it's this elite club that you enter because you know about it already. i got the omakase menu, every bite was carefully prepared in front of my eyes before being placed on my little stone tray and then popped into my mouth. it was as if centuries of preparation and thought had gone into the making of each bite; the culture and technique behind the assembly of the such, the flavor and texture profile, the quality of the ingredient... i think when i went through that unmarred black door, i went to hernia and then emerged into the mundane world upon exit. sake was phenomena. i tasted everything that the sommelier (skelter? sake master?) was describing. service was awesome and very pleasant, we had a blast with the bartender. if you can get a yes and have the cash to finance, go to shako. if not, picture how the gods eat and you got yourself a fair approximation of this meal \n",
      "\n",
      "Review (after document tokenization, removing stopwords, lemmatization):  ['give', 'star', 'often', 'unless', 'truly', 'cellar', 'meal', 'course', 'stuffy', 'fancypants', 'place', 'cellar', 'although', 'sometimes', 'shako', 'one', 'scale', 'place', 'truly', 'bottom', 'heart', 'one', 'best', 'meal', 'ever', 'adam', 'door', 'even', 'elite', 'club', 'enter', 'know', 'already', 'got', 'omakase', 'menu', 'every', 'bite', 'carefully', 'prepared', 'front', 'eye', 'placed', 'little', 'stone', 'tray', 'popped', 'mouth', 'century', 'preparation', 'thought', 'gone', 'making', 'bite', 'culture', 'technique', 'behind', 'assembly', 'flavor', 'texture', 'profile', 'quality', 'ingredient', 'think', 'went', 'unmarred', 'black', 'door', 'went', 'hernia', 'emerged', 'mundane', 'world', 'upon', 'exit', 'sake', 'phenomenon', 'tasted', 'everything', 'sommelier', 'skelter', 'sake', 'master', 'describing', 'service', 'awesome', 'pleasant', 'blast', 'bartender', 'get', 'yes', 'cash', 'finance', 'go', 'shako', 'picture', 'god', 'eat', 'got', 'fair', 'approximation', 'meal'] \n",
      "\n",
      "Review (after gensim corpus):  [(32, 1), (39, 1), (42, 2), (46, 1), (57, 1), (84, 2), (106, 1), (120, 2), (125, 1), (149, 1), (179, 1), (185, 1), (187, 1), (188, 1), (195, 3), (203, 2), (222, 1), (258, 1), (273, 2), (278, 1), (290, 1), (336, 1), (351, 1), (359, 2), (363, 1), (402, 1), (550, 1), (584, 1), (591, 1), (629, 1), (634, 1), (656, 1), (697, 1), (711, 1), (727, 1), (758, 1), (816, 1), (831, 1), (909, 1), (930, 1), (982, 1), (1018, 1), (1080, 2), (1084, 1), (1183, 1), (1217, 1), (1222, 2), (1277, 1), (1379, 1), (1435, 1), (1496, 1), (1522, 1), (1534, 1), (1549, 1), (1631, 1), (1805, 1), (1816, 1), (1873, 1), (1900, 1), (1922, 1), (1960, 1), (2028, 1), (2037, 2), (2084, 1), (2408, 1), (2422, 1), (2810, 1), (2811, 1), (2956, 1), (3031, 1), (3122, 1), (3477, 1), (3569, 1), (3602, 1), (4014, 1), (4387, 1), (4555, 1), (5018, 1), (6105, 1), (6203, 1), (8238, 1), (10005, 2), (11062, 1), (12939, 1), (13210, 1), (13247, 1), (16160, 1), (17327, 1), (23953, 1), (29363, 1)]\n"
     ]
    }
   ],
   "source": [
    "print('Review (after pre-processing): ', text, '\\n')\n",
    "print('Review (after document tokenization, removing stopwords, lemmatization): ', text5, '\\n')\n",
    "print('Review (after gensim corpus): ', corpus[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe of corpus, which tracks the restaurant that the review belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_idx</th>\n",
       "      <th>corpus</th>\n",
       "      <th>yelp_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[(18, 1), (26, 1), (32, 1), (41, 1), (69, 1), ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[(15, 1), (22, 1), (28, 1), (29, 1), (38, 1), ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[(23, 1), (26, 1), (41, 1), (57, 2), (58, 1), ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[(4, 1), (14, 1), (28, 1), (41, 2), (48, 2), (...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   restaurant_idx                                             corpus  \\\n",
       "0               0  [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...   \n",
       "1               0  [(18, 1), (26, 1), (32, 1), (41, 1), (69, 1), ...   \n",
       "2               0  [(15, 1), (22, 1), (28, 1), (29, 1), (38, 1), ...   \n",
       "3               0  [(23, 1), (26, 1), (41, 1), (57, 2), (58, 1), ...   \n",
       "4               0  [(4, 1), (14, 1), (28, 1), (41, 2), (48, 2), (...   \n",
       "\n",
       "   yelp_rating  \n",
       "0            5  \n",
       "1            4  \n",
       "2            3  \n",
       "3            5  \n",
       "4            4  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus = pd.DataFrame({'restaurant_idx':df_reviews['review_idx'], \n",
    "                          'corpus':corpus, \n",
    "                          'yelp_rating':df_reviews['rating']})\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Basic word count and bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find most frequent words in best-rated and worst-rated Yelp restaurants\n",
    "\n",
    "- \"Good\" Yelp reviews have ratings = 5 \n",
    "- \"Bad\" Yelp reviews have ratings <= 3\n",
    "\n",
    "Note that individual reviews can only be an integer from 1 to 5. Overall average Yelp rating for a restaurant, however, is capable of increments of 0.5 (such as 4.5/5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best-rating reviews\n",
    "\n",
    "idx_good = df_reviews[df_reviews['rating'] == 5].index\n",
    "idx_good_doc = [t for t,j in df_corpus['restaurant_idx'].iteritems() if j in idx_good] # index of docs belonging to those restaurants\n",
    "\n",
    "subcorpus_good = []\n",
    "subcorpus_good = [(subcorpus_good + doc) for idx, doc in df_corpus.loc[idx_good_doc]['corpus'].iteritems()]\n",
    "\n",
    "# Worst-rating reviews\n",
    "\n",
    "idx_bad = df_reviews[df_reviews['rating'] <= 3 ].index\n",
    "idx_bad_doc = [t for t,j in df_corpus['restaurant_idx'].iteritems() if j in idx_bad] # index of docs belonging to those restaurants\n",
    "\n",
    "subcorpus_bad = []\n",
    "subcorpus_bad = [(subcorpus_bad + doc) for idx, doc in df_corpus.loc[idx_bad_doc]['corpus'].iteritems()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print top 10 words for \"good\" and \"bad\" Yelp reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for GOOD-rating Yelp reviews: \n",
      "\n",
      "food 35214\n",
      "good 27209\n",
      "place 24077\n",
      "dish 20665\n",
      "like 19264\n",
      "great 18719\n",
      "restaurant 18666\n",
      "one 18183\n",
      "service 16912\n",
      "would 16621\n",
      "\n",
      "\n",
      "Top 10 words for BAD-rating Yelp reviews: \n",
      "\n",
      "food 14147\n",
      "good 9456\n",
      "dish 8355\n",
      "place 8224\n",
      "restaurant 7841\n",
      "service 6925\n",
      "like 6893\n",
      "great 6816\n",
      "one 6390\n",
      "would 5800\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Good-rating reviews\n",
    "\n",
    "total_word_count_good = collections.defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(subcorpus_good):\n",
    "    total_word_count_good[word_id] += word_count\n",
    "\n",
    "sorted_word_count_good = sorted(total_word_count_good.items(), key=lambda w: w[1], reverse=True) \n",
    "\n",
    "print('Top 10 words for GOOD-rating Yelp reviews:','\\n')\n",
    "for word_id, word_count in sorted_word_count_good[:10]:\n",
    "    print(dictionary.get(word_id), word_count)\n",
    "print('\\n')\n",
    "\n",
    "# Bad-rating reviews\n",
    "\n",
    "total_word_count_bad = collections.defaultdict(int)\n",
    "for word_id, word_count in itertools.chain.from_iterable(subcorpus_bad):\n",
    "    total_word_count_bad[word_id] += word_count\n",
    "\n",
    "sorted_word_count_bad = sorted(total_word_count_bad.items(), key=lambda w: w[1], reverse=True) \n",
    "\n",
    "print('Top 10 words for BAD-rating Yelp reviews:','\\n')\n",
    "for word_id, word_count in sorted_word_count_bad[:10]:\n",
    "    print(dictionary.get(word_id), word_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b>: As seen from the overlap between top-10 \"good\"/\"bad\" words from a simple bag of words count, we will need more sophisticated tools to parse keywords associated with \"good\" or \"bad\" ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. tf-idf EDA\n",
    "\n",
    "In the previous section, we did simple pre-processing and simply took token frequency. Here, we experiment with using gensim's [tf-idf](https://radimrehurek.com/gensim/models/tfidfmodel.html) to identify most important words in each document. This is accomplished with their algorithm by down-weighting shared words (between documents) beyond simply stopwords, ensuring that common words don't show up as key words. Conversely, document-specific words are weighted highly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Experimenting with tf-idf on a Yelp review\n",
    "\n",
    "We generate tfidf weights for a single document (Yelp review) to see how tf-idf performs. The tf-idf model is generated on the entire corpus of documents (i.e. reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf weights:  \n",
      " [(0, 0.11605235285752101), (1, 0.055517904959346144), (2, 0.058550703583362056), (3, 0.01923654735257033), (4, 0.027415914582950895)] \n",
      "\n",
      "Top 5 weighted words:\n",
      "oden 0.43697383680554125\n",
      "dashi 0.2652405475558776\n",
      "uh 0.2273065414231621\n",
      "mochi 0.19016016546668416\n",
      "spaghetti 0.1868451957856557\n",
      "\n",
      "\n",
      "Text:  \n",
      " davelle uh oden uh foodie trippin get order right uh shawty look good eatin oden oden dish drink dashi davelle oden moonlight xxxtentacion rip everything amazing u dining tiny cozy cramped beautiful little spot got oden set karaage cod spaghetti hokkaido spaghetti uni tomato cold dish topped kinda optional light cheese drink dashi aaaalllll dish good soft blanched skinless savory daikon served spicy yuzu paste use sparingly pretty big kick red miso paste soft mushy perfectly cooked heart shaped daikon mochi lightly fried bag soft gooey delicious mochi def drink dashi scallion enoki mushroom ginger hanpen white fish cake soft texture airy typical fish cake denseness fishcake delicious served spicy yuzu paste sausage served japanese mustard yummy bamboo shoot cooked enough left slight hate mushy bamboo shoot dashi similar taste mochi karaage soft juicy chicken lightly battered medium crisp cod spaghetti aka mentaiko pasta light cod roe taste fishy delicious hokkaido style spaghetti uni delicious much uni guess maybe another variation mentaiko liquor license sake soju cocktail beer wine went tonight quiet small space sure peak time usually wait\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "# Create a new TfidfModel using the corpus: tfidf\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "# Calculate the tfidf weights of doc: tfidf_weights\n",
    "doc = corpus[0]\n",
    "tfidf_weights = tfidf[doc]\n",
    "\n",
    "# Print the first five weights\n",
    "print('tfidf weights: ', '\\n', tfidf_weights[:5], '\\n')\n",
    "\n",
    "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 weighted words\n",
    "print('Top 5 weighted words:')\n",
    "for term_id, weight in sorted_tfidf_weights[:5]:\n",
    "    print(dictionary[term_id], weight)\n",
    "\n",
    "print('\\n')\n",
    "print('Text: ','\\n', ' '.join(corpus_tokenized[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion</b>: It appears that if we take a document to be a single review, tf-idf may pick keywords that are specific to the reviewed restaurant's cuisine. Although this may be useful for identifying what food the restaurant serves, we are more interested in what the reviewer thought of the food, service, etc. \n",
    "\n",
    "Next, we try taking a document to be the the concatenation of all reviews belonging to a single restaurant to see if we get more relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Experimenting with tf-idf on all reviews belonging to a single restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf weights:  \n",
      " [(0, 0.0385683994677437), (1, 0.018717773450899693), (2, 0.01961377610979211), (3, 0.006518710429663028), (4, 0.00919997238797367)] \n",
      "\n",
      "Top 5 weighted words:\n",
      "oden 0.17360491863449606\n",
      "oden 0.14467076552874672\n",
      "gobo 0.13137044585937177\n",
      "ada 0.10397982332595031\n",
      "dashi 0.0903979302813469\n"
     ]
    }
   ],
   "source": [
    "# Combine a single restaurant's reviews into one document (Davelle, first entry in df_nyt_yelp restaurant database)\n",
    "\n",
    "restaurant_idx = 0\n",
    "df = df_corpus[df_corpus['restaurant_idx']==0]\n",
    "doc = df['corpus'].tolist()\n",
    "doc = list(itertools.chain(*doc))\n",
    "\n",
    "tfidf_weights = tfidf[doc]\n",
    "\n",
    "# Print the first five weights\n",
    "print('tfidf weights: ', '\\n', tfidf_weights[:5], '\\n')\n",
    "\n",
    "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
    "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "# Print the top 5 weighted words\n",
    "print('Top 5 weighted words:')\n",
    "for term_id, weight in sorted_tfidf_weights[:5]:\n",
    "    print(dictionary[term_id], weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> Top tf-idf keywords still seem to refer to the restaurant's type of cuisine more so than taste/food. It's likely that tf-idf, because it is designed to down-weight common words between documents, will actually leave out the phrases we want regarding food, service, and quality, since these are likely to appear across all documents (i.e. reviews)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Summary\n",
    "\n",
    "We conclude this section with a pipeline setting up for converting documents (Yelp reviews) into token-wordcount mappings. As seen from the top wordcounts of \"best-rating\" and \"worst_rating\" Yelp reviews, there are many confounding terms that probably won't serve as good predictors for \"good\" or \"bad\" restaurants. \n",
    "\n",
    "Next, we'll experiment with word embeddings, sentiment analysis, CountVectorizer train-test-split on \"good\"/\"bad\" restaurants, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification: \"good\"/\"bad\" reviews\n",
    "\n",
    "Here, we use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to train/predict review labels: \"good\" or \"bad\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Generating \"good\" & \"bad\" review labels\n",
    "\n",
    "Like the previous section, we'll take \"good\" ratings = 5 and \"bad\" ratings <= 3. As a result, we ignore reviews with a \"4\"-rating for now. \n",
    "\n",
    "The rationale is that these can contain a mix of positive/negative comments - negative comments explaining why the restaurant is not a 5, but also positive comments explaining why the restaurant would be > 3. Such a mix may confound our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate dataframe for classification train/test\n",
    "\n",
    "Generate dataframe we will be working with, which contains only reviews of <=3 & = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool_count</th>\n",
       "      <th>elite_count</th>\n",
       "      <th>friend_count</th>\n",
       "      <th>funny_count</th>\n",
       "      <th>length_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>useful_count</th>\n",
       "      <th>user_count</th>\n",
       "      <th>review_idx</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1771</td>\n",
       "      <td>5</td>\n",
       "      <td>345</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>Davelle, uh, oden, uh. Foodie, why you trippin...</td>\n",
       "      <td>4</td>\n",
       "      <td>Jennie C.</td>\n",
       "      <td>0</td>\n",
       "      <td>davelle open food tripping get order right sha...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>Lovely little 16 seater at the south end of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Adam W.</td>\n",
       "      <td>0</td>\n",
       "      <td>lovely little seated south end le went late lu...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>2</td>\n",
       "      <td>1583</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>If you enjoy an small intimate cafe with diffe...</td>\n",
       "      <td>8</td>\n",
       "      <td>Maria S.</td>\n",
       "      <td>0</td>\n",
       "      <td>enjoy small intimate cafe different type japan...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cool_count  elite_count friend_count funny_count  length_count  rating  \\\n",
       "0          4            1           45           2          1771       5   \n",
       "3          1            1           55           0           486       5   \n",
       "6          2            1          277           2          1583       5   \n",
       "\n",
       "  review_count review_date                                        review_text  \\\n",
       "0          345  2018-06-18  Davelle, uh, oden, uh. Foodie, why you trippin...   \n",
       "3           58  2018-06-27  Lovely little 16 seater at the south end of th...   \n",
       "6           96  2018-03-20  If you enjoy an small intimate cafe with diffe...   \n",
       "\n",
       "  useful_count user_count  review_idx  \\\n",
       "0            4  Jennie C.           0   \n",
       "3            0    Adam W.           0   \n",
       "6            8   Maria S.           0   \n",
       "\n",
       "                                   text_preprocessed label  \n",
       "0  davelle open food tripping get order right sha...  good  \n",
       "3  lovely little seated south end le went late lu...  good  \n",
       "6  enjoy small intimate cafe different type japan...  good  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab \"good\" & \"bad\" review indices\n",
    "idx_class = idx_good.append(idx_bad)\n",
    "\n",
    "# Filter dataframe for only \"good\" and \"bad\" reviews. Save to 'df_class'\n",
    "df_class = df_reviews.loc[idx_class]\n",
    "\n",
    "# Include pre-processed text in new column: 'text_preprocessed'\n",
    "text_preprocessed = [' '.join(doc) for doc in text_tokenized]\n",
    "df = pd.DataFrame({'text':text_preprocessed})\n",
    "df_class['text_preprocessed'] = df.loc[idx_class]\n",
    "\n",
    "# Assign \"good\" or \"bad\" label\n",
    "df_class.loc[idx_good, 'label'] = 'good'\n",
    "df_class.loc[idx_bad, 'label'] = 'bad'\n",
    "\n",
    "df_class.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 CountVectorizer for train/test split\n",
    "\n",
    "Use CountVectorizer to convert text to a sparse <b>document-term matrix (DTM)</b> of token counts, where each column is a <b>token</b> from the corpus vocabulary (generated from training set), each row is a <b>document</b> (a Yelp review), and the values are token frequency. Train & fit to set up for next section of predicting \"good\"/\"bad\" reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaaaaaaaand', 'aaaaaaaand', 'aaaaaamazing', 'aaaaall', 'aaaalllll', 'aaaamazing', 'aaaand', 'aaaanyway', 'aaalll', 'aaanndd', 'aaawwweeesome', 'aah', 'aahhhhh', 'aaron', 'aaswadikkan', 'ab', 'aback', 'abaiyin', 'abandon', 'abandoned']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df_class.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_class['text_preprocessed'], y, test_size=.33, random_state = 53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Learn the \"vocabulary\" of the training set & transform into 'document-term' matrix\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "#  Use the fitted vocabulary to build a DTM from the testing data (IGNORES tokens it hasn't seen before)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiny sample of resulting sparse DTM, where rows = Yelp reviews, columns = vocabulary generated from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DTM:  (34497, 22933)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension</th>\n",
       "      <th>apprehensive</th>\n",
       "      <th>apprentice</th>\n",
       "      <th>approach</th>\n",
       "      <th>approached</th>\n",
       "      <th>approaching</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>appropriated</th>\n",
       "      <th>appropriately</th>\n",
       "      <th>appropriation</th>\n",
       "      <th>approval</th>\n",
       "      <th>approve</th>\n",
       "      <th>approved</th>\n",
       "      <th>approximate</th>\n",
       "      <th>approximated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apprehension  apprehensive  apprentice  approach  approached  approaching  \\\n",
       "0             0             0           0         0           0            0   \n",
       "\n",
       "   appropriate  appropriated  appropriately  appropriation  approval  approve  \\\n",
       "0            0             0              0              0         0        0   \n",
       "\n",
       "   approved  approximate  approximated  \n",
       "0         0            0             0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape of DTM: ', count_train.shape)\n",
    "pd.DataFrame(count_train[0,1000:1015].toarray(), columns=count_vectorizer.get_feature_names()[1000:1015])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's apparent that there will be many duplicate versions/misspellings of a word, which might confound results and cause some terms to be downweighted in importance. Not clear how to correct for these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Naive Bayes classifier\n",
    "\n",
    "The Naive Bayes model is commonly used for testing NLP classification problems. It is rooted in probability ([Bayes theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)) and generates predictions based on past data - given prior training data with features and labelled outcomes, what can we predict with our set of test observations and their features? The label it predicts for each observation is based on its calculation of the likeliest out of the possible labels. See [here](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/) for a good explanation.\n",
    "\n",
    "Here, each word from `CountVectorizer` acts as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predicted \"good\"/\"bad\" reviews\n",
    "\n",
    "Use sklearn's [naive_bayes](http://scikit-learn.org/stable/modules/naive_bayes.html) module to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8912429378531074 \n",
      "\n",
      "Confusion matrix: \n",
      " [[9909  870]\n",
      " [ 978 5235]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Accuracy score:', score, '\\n')\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['good', 'bad'])\n",
    "print('Confusion matrix:','\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier performed fairly well. Let's inspect the model to actually see what it has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad [(-13.957909021660562, 'aaaanyway'), (-13.957909021660562, 'aaalll'), (-13.957909021660562, 'abaiyin'), (-13.957909021660562, 'abandoning'), (-13.957909021660562, 'abbreviation'), (-13.957909021660562, 'abercrombie'), (-13.957909021660562, 'abhorrent'), (-13.957909021660562, 'abiding'), (-13.957909021660562, 'abject'), (-13.957909021660562, 'abnormal'), (-13.957909021660562, 'aboard'), (-13.957909021660562, 'abominable'), (-13.957909021660562, 'abomination'), (-13.957909021660562, 'abort'), (-13.957909021660562, 'abortion'), (-13.957909021660562, 'abounding'), (-13.957909021660562, 'abrasion'), (-13.957909021660562, 'abrasiveness'), (-13.957909021660562, 'abricots'), (-13.957909021660562, 'absorbent')] \n",
      "\n",
      "good [(-5.4960171460294145, 'taste'), (-5.4800805537666015, 'try'), (-5.4475390555924506, 'experience'), (-5.44633156902996, 'come'), (-5.383390763625055, 'definitely'), (-5.373992198201417, 'meal'), (-5.147151094634388, 'amazing'), (-5.147151094634388, 'really'), (-5.135586844188824, 'menu'), (-5.119067208229271, 'best'), (-5.025168386794649, 'time'), (-4.98938546626421, 'delicious'), (-4.9805100434787, 'like'), (-4.950909573702409, 'service'), (-4.87154582950409, 'restaurant'), (-4.852929165342205, 'dish'), (-4.737915392656241, 'good'), (-4.681968192600431, 'great'), (-4.551344187721433, 'place'), (-4.214472857272661, 'food')]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20], '\\n')\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results make sense. Negative words such as \"abhorrent\" and \"abominable\" feature prominently in \"bad\" reviews, while \"good\" reviews have positive descriptors such as \"delicious\" and \"amazing\". \n",
    "\n",
    "It is interesting to note features that by themselves are neutral, such as \"service\". Since they are included in \"good\" reviews, it seems service is an important factor and is conducted well in \"good\" reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check examples of false positives\n",
    "\n",
    "Where \"bad\" reviews were incorrectly classified as \"good\" reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 example:  \n",
      "\n",
      "Pre-processed:  dr price average good would come way come back esp bc wait area put name two ahead time wait awful would way long live close friend decided share bunch plate tasted good outstanding got lichen adult carpus sun sweet strong particularly complex interesting got kimchi patella softer risotto longer like expected much kick kimchi broccoli rare probably best thing got charred case great touch overall small tocchi soup remember must great ruffle mac cheese rich much calm action ruffle oil definitely present little oily drink several plate ran u lot money good food feel worth \n",
      "\n",
      "Actual review:  TL;DR: pricy but average. It was good, but I wouldn't come out of my way to come back, esp. bc the wait is long.. . I was in the area and put my name down for two ahead of time. The wait was 1.5 hrs on a a Saturday- not awful, but would have been way too long if I didn't live close. . . Friend and I decided to share a bunch of plates which all tasted good, but not outstanding. I got the lychee Adult Capri Sun; sweet, strong but not particularly complex or interesting. We got:. . 1) Kimchi paella: softer, more risotto / congee like than I expected, and not much of a kick from the kimchi. 2) Broccoli rabe: probably the best of all the things we got. The charred cashews a great touch, but overall it was small. 3) gnocchi - very soupy is all I remember so it must not have been that great. 4) truffle Mac and cheese - rich, not much clam action. Truffle oil was definitely present if a little oily . . With drinks and several plates, this ran us ~$45. a lot of money for good food but I didn't feel it was worth it. \n",
      "\n",
      "First 10 examples: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15829    super excited come love love asia sandwiched s...\n",
       "66797    everything restaurant beautiful food good litt...\n",
       "16699    first visit new union square cafe wish still o...\n",
       "67042    went anniversary restaurant beautiful experien...\n",
       "43967    impressed food meat real flavor bulgolgi also ...\n",
       "61320    black wanted magnificent instead middling want...\n",
       "36189    solid star restaurant inviting trend make feel...\n",
       "35214    due forgo two large wood burning oven dominate...\n",
       "25541    dr price average good would come way come back...\n",
       "24000    first meal new year son respect significance n...\n",
       "Name: text_preprocessed, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives = X_test[y_test < pred]\n",
    "print('1 example: ','\\n')\n",
    "print('Pre-processed: ', false_positives[25541], '\\n')\n",
    "print('Actual review: ', df_reviews.loc[25541, 'review_text'], '\\n')\n",
    "print('First 10 examples: ')\n",
    "false_positives.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, a likely reason some reviews were false positives was due to the prevalence of positive words (ex. \"good\", \"outstanding\") in the midst of a negative evaluation with a few turns of phrase (ex. \"It was good, but I wouldn't come out of my way to come back\"). \n",
    "\n",
    "In fact, in our example, pre-processing and removing stopwords may have removed tokens that would have caused the review to be correctly labelled as \"bad\", since they were critical parts of negative turns of phrase. Phrases/words such as \"but not outstanding\", \"good food but I didn't feel it was worth it\" are lost as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check examples of false negatives\n",
    "\n",
    "Where \"good\" reviews were incorrectly classified as \"bad\" reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 example:  \n",
      "\n",
      "Pre-processed:  love place went first time ordered salt pepper chicken rice tofu vegetable rice beef tendon dish rice stayed meal complimentary pork soup tea nice soup tea like place mama lee made soup tea heart kindness know restarurant complimentary thing taste kinda bland shitty sometimes felt like home eating meal rice came separately another bowl even tho ordered rice worth \n",
      "\n",
      "Actual review:  Love this place. I went there for the first time and ordered salt and pepper chicken over rice, tofu with vegetable over rice,  and beef tendon dish over rice. We stayed for the meal and they have complimentary pork soup and tea. . . It's a very nice soup and tea, this is not like other places, Mama Lee made these soup and tea with her heart (kindness). You know how other restarurant complimentary things taste kinda just bland and shitty sometimes, this is not at all!   I felt like home eating all the meals. . . The rice came separately with another bowl even tho you ordered \"______over rice\"  . . It is worth it. \n",
      "\n",
      "First 10 examples: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14283    love place bummer ca since come visit nyc ever...\n",
       "18056    love place went first time ordered salt pepper...\n",
       "32238    brother stopped quick lunch food great loved a...\n",
       "60373    cute kitschy vibe decent price strong drink cu...\n",
       "54334    true service bad food take awhile come pizza g...\n",
       "46904    despite poke craze taking entire city place ju...\n",
       "60155    amazing place noodle tasty take low spice othe...\n",
       "14436    visited tim ho wan couple time must say go dim...\n",
       "13951    came tuesday evening line door already pretty ...\n",
       "7329     rice noodle mi fen decently made color texture...\n",
       "Name: text_preprocessed, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives = X_test[y_test > pred]\n",
    "\n",
    "print('1 example: ','\\n')\n",
    "print('Pre-processed: ', false_negatives[18056],'\\n')\n",
    "print('Actual review: ', df_reviews.loc[18056, 'review_text'], '\\n')\n",
    "print('First 10 examples: ')\n",
    "false_negatives.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the false positives, these reviews tend to have a mixed bag of vocabulary associated with both \"good\" & \"bad\" reviews. In the above example for instance, there are many positive words (ex. \"love\", \"nice\") but also negative words that would probably trigger a \"bad\" review (ex. \"shitty\", \"bland\") even though the reviewer used these terms to describe other competing restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we: \n",
    "- Set up a pipeline for NLP - including pre-processing, generating a corpus, bag of words, CountVectorizer sparse DTM, etc. \n",
    "- Discovered words (and word frequencies) associated with \"good\" & \"bad\" reviews.\n",
    "- Successfully explored classification for \"good\" & \"bad\" reviews. Our Naive Bayes classifier worked fairly well, with an accuracy score of ~90%. \n",
    "\n",
    "Now that we have quantified terms associated with \"good\"/\"bad\" reviews, as well as experimented with a classifier for predicting such reviews, we proceed with incorporating NYT data in our next notebook (`data_EDA_timeseries`). \n",
    "\n",
    "The results in this section will allow us to determine whether the introduction of NYT reviews has any influence on Yelp reviews. For instance, introducing NYT reviews may shift the emphasis on different terms predicting \"good\"/\"bad\" reviews (ex. \"NYT\", \"service\", \"hole-in-the-wall\", \"critic\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
